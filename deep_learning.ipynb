{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build my own deep learning functions\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Learn by practicing. Notations follow Andrew Ng's Coursera deep learning course."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the forward_prop function\n",
    "Note: If there is error while importing python modules while running this notebook in vscode, make sure the both the vscode python interpreter and ipython kernal are both set properly. \n",
    "\n",
    "### Model structure\n",
    "The model consist of L-1 relu layers and one sigmoid layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1) \n",
    "# TODO: with certain seeds, e.g. seed=1, the cost generates NAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below function taken from course assignments\n",
    "def load_data():\n",
    "    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:])\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:])\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    '''\n",
    "    Z: Input to the activate function\n",
    "\n",
    "    A: Output of the relu function\n",
    "    '''\n",
    "    A = np.maximum(0, Z)\n",
    "    assert(np.min(A) >= 0.0)\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X, Y, parameters):\n",
    "    '''\n",
    "    # TODO: What's the row # variable?\n",
    "    X: Input data. (n0???, m). n0: feature #; m: # of examples\n",
    "    Y: Labels. (1, m)\n",
    "    parameters: The model parameters\n",
    "\n",
    "    cost: The return\n",
    "    '''\n",
    "    L = len(parameters) // 2\n",
    "    Xl = X\n",
    "    m = Y.shape[1]\n",
    "    for l in range(1, L):\n",
    "        # print('l=', l)\n",
    "        W = parameters['W'+str(l)]\n",
    "        b = parameters['b'+str(l)]\n",
    "\n",
    "        assert(W.shape[0] == b.shape[0])\n",
    "        Z = np.dot(W, Xl) + b\n",
    "        A = relu(Z)\n",
    "        Xl = A\n",
    "    ZL = np.dot(parameters['W'+str(L)], Xl) + parameters['b'+str(L)]\n",
    "    AL = 1 / (1 + np.exp(-ZL)) # sigmoid\n",
    "    # print('ZL=', ZL)\n",
    "    # print('AL=', AL)\n",
    "    print('### debug ###: AL.max(), AL.min()=', AL.max(), AL.min())\n",
    "\n",
    "    J = - np.dot(Y, np.log(AL).T) - np.dot(1 - Y, np.log(1 - AL).T)\n",
    "    cost = np.squeeze(np.sum(J)) / m\n",
    "    assert(cost.shape == ())\n",
    "\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and pre-processing\n",
    "train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes = load_data()\n",
    "# print('train_set_x_orig.shape=', train_set_x_orig.shape)\n",
    "\n",
    "# plt.imshow(train_set_x_orig[7])\n",
    "# plt.show()\n",
    "\n",
    "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n",
    "\n",
    "# print('train_set_x_flatten.shape=', train_set_x_flatten.shape)\n",
    "# print('test_set_x_flatten.shape=', test_set_x_flatten.shape)\n",
    "# print(train_set_x_flatten)\n",
    "# print(train_set_x_flatten.max())\n",
    "\n",
    "train_set_x = train_set_x_flatten / 255.0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson learned\n",
    "When the weights are not initailized small, aka, without *0.01, the cost computation gives lots of NAN because the output are either too small or too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dims = [train_set_x.shape[0], 8, 4, 1]\n",
    "parameters = {}\n",
    "for i in range(1, len(layer_dims)):\n",
    "    parameters['W'+str(i)] = np.random.rand(layer_dims[i], layer_dims[i-1]) * 0.01 # the down-scaling is important\n",
    "    parameters['b'+str(i)] = np.zeros((layer_dims[i], 1))\n",
    "    # print(parameters['W'+str(i)].shape, parameters['b'+str(i)].shape)\n",
    "\n",
    "tmp = forward_prop(train_set_x, train_set_y_orig, parameters)\n",
    "# print('len(train_set_y_orig)=', len(train_set_y_orig))\n",
    "# print('train_set_y_orig.shape', train_set_y_orig.shape)\n",
    "print(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "879bf236243f5f3c3f16927df85609c2f6dbedfe1e86c1d37000aa722c5f092b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
